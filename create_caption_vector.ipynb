{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c98324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install numpy\n",
    "%pip install sentencepiece protobuf\n",
    "%pip install python-dotenv==1.2.1\n",
    "%pip install openai==2.16.0\n",
    "%pip install azure-ai-inference==1.0.0b9\n",
    "%pip install sentence-transformers==5.2.2 tiktoken==0.12.0\n",
    "%pip install fastembed==0.7.4\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import numpy  as np\n",
    "import scipy  as sp\n",
    "from typing        import List\n",
    "from dotenv        import load_dotenv\n",
    "from logging       import Logger, getLogger\n",
    "from openai        import OpenAI, AsyncOpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.asyncio  import tqdm_asyncio\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from delta       import configure_spark_with_delta_pip\n",
    "\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from sentence_transformers     import SentenceTransformer\n",
    "from fastembed                 import TextEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fe2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder\\\n",
    "            .config(\"spark.sql.sources.commitProtocolClass\", \"org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol\")\\\n",
    "            .config(\"spark.sql.parquet.output.committer.class\", \"org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\")\\\n",
    "            .config(\"spark.mapreduce.fileoutputcommitter.marksuccessfuljobs\",\"false\")\\\n",
    "            .config(\"spark.sql.adaptive.enabled\", True)\\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"auto\")\\\n",
    "            .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"100MB\")\\\n",
    "            .config(\"spark.sql.adaptive.coalescePartitions.enabled\", True)\\\n",
    "            .config(\"spark.sql.dynamicPartitionPruning.enabled\", True)\\\n",
    "            .config(\"spark.sql.autoBroadcastJoinThreshold\", \"10MB\")\\\n",
    "            .config(\"spark.sql.session.timeZone\", \"Asia/Tokyo\")\\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "            .config(\"spark.databricks.delta.write.isolationLevel\", \"SnapshotIsolation\")\\\n",
    "            .config(\"spark.databricks.delta.optimizeWrite.enabled\", True)\\\n",
    "            .config(\"spark.databricks.delta.autoCompact.enabled\", True)\n",
    "            # Delta Lake 用の SQL コミットプロトコルを指定\n",
    "            # Parquet 出力時のコミッタークラスを指定\n",
    "            # Azure Blob Storage (ABFS) 用のコミッターファクトリを指定\n",
    "            # '_SUCCESS'で始まるファイルを書き込まないように設定\n",
    "            # AQE(Adaptive Query Execution)の有効化\n",
    "            # パーティション数を自動で調整するように設定\n",
    "            # シャッフル後の1パーティションあたりの最小サイズを指定\n",
    "            # AQEのパーティション合成の有効化\n",
    "            # 動的パーティションプルーニングの有効化\n",
    "            # 小さいテーブルのブロードキャスト結合への自動変換をするための閾値調整\n",
    "            # SparkSessionのタイムゾーンを日本標準時刻に設定\n",
    "            # Delta Lake固有のSQL構文や解析機能を拡張モジュールとして有効化\n",
    "            # SparkカタログをDeltaLakeカタログへ変更\n",
    "            # Delta Lake書き込み時のアイソレーションレベルを「スナップショット分離」に設定\n",
    "            # 書き込み時にデータシャッフルを行い、大きなファイルを生成する機能の有効化\n",
    "            # 書き込み後に小さなファイルを自動で統合する機能の有効化\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env ファイルを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# 環境変数の取得\n",
    "AI_FOUNDRY_ENDPOINT = os.environ.get(\"AI_FOUNDRY_ENDPOINT\")\n",
    "AI_FOUNDRY_API_KEY  = os.environ.get(\"AI_FOUNDRY_API_KEY\")\n",
    "AI_FOUNDRY_MODEL    = os.environ.get(\"AI_FOUNDRY_MODEL\")\n",
    "MAX_TOKENS          = os.environ.get(\"MAX_TOKENS\")\n",
    "TEMPERATURE         = os.environ.get(\"TEMPERATURE\")\n",
    "TOP_P               = os.environ.get(\"TOP_P\")\n",
    "\n",
    "# メモ：\n",
    "# ウィジット経由でのパラメータの取得方法では、無条件にパラメータの型がStringに変換されてしまう\n",
    "# そのため、受け取ったパラメータを適切に型変換する必要がある\n",
    "MAX_TOKENS  = int(MAX_TOKENS)\n",
    "TEMPERATURE = float(TEMPERATURE)\n",
    "TOP_P       = float(TOP_P)\n",
    "\n",
    "\n",
    "# 簡易デバッグ用\n",
    "print(f'AI_FOUNDRY_ENDPOINT: {AI_FOUNDRY_ENDPOINT}')\n",
    "print(f'AI_FOUNDRY_API_KEY:  {AI_FOUNDRY_API_KEY}')\n",
    "print(f'AI_FOUNDRY_MODEL:    {AI_FOUNDRY_MODEL}')\n",
    "print(f'MAX_TOKENS:          {MAX_TOKENS}')\n",
    "print(f'TEMPERATURE:         {TEMPERATURE}')\n",
    "print(f'TOP_P:               {TOP_P}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19b084",
   "metadata": {},
   "source": [
    "# 場所の文脈ベクトル化：アプローチの進化と実装課題\n",
    "\n",
    "## 1. 目的と課題 (Objective & Challenge)\n",
    "- **目的**: 広告LP (Landing Page) と物理的な「場所」を高次元でマッチングさせ、高精度な広告配信を実現する。\n",
    "- **課題**: 単なる「場所名・施設名」の埋め込みでは、その場所が持つ**「雰囲気・客層・利用文脈」といった深い意味空間（Context）**を捉えきれず、マッチング精度が頭打ちになる。\n",
    "\n",
    "## 2. アプローチの変遷 (Evolution)\n",
    "当初の「LLMによる一般的な想像」から、実データであるADID（広告ID）に基づく「行動からの逆算」へと方針を転換した。\n",
    "\n",
    "| 比較項目 | 初期案：LLMによる想像 (Generative) | **修正案：ADID行動解析 (Bayesian Approach)** |\n",
    "| :--- | :--- | :--- |\n",
    "| **アプローチ** | **Top-down (演繹的)**<br>場所名から一般的なイメージを降ろしてくる手法。 | **Bottom-up (帰納的)**<br>個々の「来訪者(ADID)」の集合から、場所の意味を積み上げる手法。 |\n",
    "| **情報の源泉** | **LLMの内部知識 (Frozen Weights)**<br>学習データに含まれる過去の知識や通説。 | **物理行動ログ (Observed Data)**<br>実際にその場所に足を運んだADIDの移動履歴という「事実」。 |\n",
    "| **文脈の解像度** | **ステレオタイプ (Stereotypical)**<br>画一的なペルソナになりがち。 | **実態の反映 (Empirical)**<br>場所ごとの固有の客層・文脈を捉える。 |\n",
    "| **情報の鮮度** | **静的 (Static)**<br>モデルの学習時期に依存。 | **動的 (Dynamic)**<br>直近のログを使用し、トレンドや季節性を反映可能。 |\n",
    "\n",
    "## 3. 理論モデル：ベイズ推定と行動ログによる文脈抽出\n",
    "\n",
    "「場所の意味（Context）」を、静的な属性ではなく、**そこに集まる個々のエージェント（ADID）が持つ目的意識の期待値**として定義する。\n",
    "\n",
    "### 3.1 変数定義\n",
    "- $L$: Location（対象となる場所・施設）\n",
    "- $A$: Agent / ADID（個々のユーザー）\n",
    "- $M$: Meaning / Context（場所が持つ意味空間）\n",
    "- $\\mathbf{v}$: 埋め込みベクトル空間（Embedding Space, $\\mathbb{R}^d$）\n",
    "\n",
    "### 3.2 ユーザー分布の事後確率推定\n",
    "まず、観測された行動ログから、ある場所 $L$ に特定のユーザー $A$ が存在する事後確率 $P(A|L)$ を求める。\n",
    "\n",
    "$$\n",
    "P(A | L) \\propto P(L | A) P(A)\n",
    "$$\n",
    "\n",
    "### 3.3 個別文脈の生成：多面的推論と平均ベクトル (Multi-Hypothesis Embedding)\n",
    "特定のユーザー $A$ が場所 $L$ にいるときの「意味」を一意に決めるのではなく、**Unity Catalog (Delta Lake)** に格納されたリッチな属性データに基づき、LLMに多様な可能性を推論させる。\n",
    "\n",
    "#### (1) 入力データの構築 (Feature Construction)\n",
    "ユーザー $A$ を定義するプロンプト $\\mathbf{x}_A$ を、以下のテーブル群から構成する：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_A \\leftarrow \\{ \\mathbf{d}_{\\text{geo}}, \\mathbf{d}_{\\text{demo}}, \\mathbf{d}_{\\text{cohort}}, \\mathbf{d}_{\\text{hist}} \\}\n",
    "$$\n",
    "\n",
    "- **`relational_address_jp`**: 居住地・勤務地（生活圏の特定）\n",
    "- **`mobilewalla_agegender`, `mobaku_agegender`**: 性別・年代（デモグラフィック属性）\n",
    "- **`relational_cohortlist`**: 生活行動・興味関心（サイコグラフィック属性）\n",
    "- **`relational_spot`**: 過去の行動履歴（コンテキストの補強）\n",
    "\n",
    "#### (2) 多面的推論 (Generative Inference)\n",
    "LLMに対し、「この属性を持つ $A$ が 場所 $L$ にいる目的と行動」について、**$K$ 個の仮説（Hypotheses）**を生成させる（例: $K \\approx 20$）。\n",
    "\n",
    "$$\n",
    "H_{A,L} = \\{ h_1, h_2, \\dots, h_K \\} \\quad \\text{where } h_i \\sim \\text{LLM}(\\text{Prompt}(\\mathbf{x}_A, L))\n",
    "$$\n",
    "\n",
    "#### (3) ベクトル化と集約 (Embedding & Aggregation)\n",
    "生成された各仮説 $h_i$ を **SentenceTransformer ($\\phi$)** を用いて埋め込みベクトルに変換し、それらの平均ベクトルを計算する。\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{A,L} = \\frac{1}{K} \\sum_{i=1}^{K} \\phi(h_i)\n",
    "$$\n",
    "\n",
    "### 3.4 場所の意味の周辺化 (Final Context Vector)\n",
    "最終的な場所 $L$ の意味分布 $P(M | L)$ は、ユーザー $A$ に関して周辺化（Marginalize）することで得られる。\n",
    "これをベクトル空間における**期待値**として解釈すると、場所の文脈ベクトル $\\mathbf{v}_L$ は以下のように定式化される。\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_L = \\sum_{A \\in \\mathcal{A}} \\mathbf{v}_{A,L} \\cdot P(A | L)\n",
    "$$\n",
    "\n",
    "これにより、単純な施設名の埋め込みではなく、**「ADIDの集合が、その場所でどのような目的を持って行動したか」**を表現する高精度なベクトルが得られる。\n",
    "\n",
    "## 4. 実装の壁 (The Computational Wall)\n",
    "上記のモデルは理論的に正しいが、物理的な計算リソースの限界に直面している。\n",
    "\n",
    "### パラメータ規模\n",
    "- **ADID数 ($N_A$)**: $\\approx 1$億 ($10^8$)\n",
    "- **場所数 ($N_L$)**: $\\approx 2,500$ ($2.5 \\times 10^3$)\n",
    "\n",
    "### 課題\n",
    "全ての組み合わせについて $P(M | A, L)$ をLLMで推論・計算しようとすると、計算量は $N_A \\times N_L$ のオーダーとなる。\n",
    "\n",
    "$$\n",
    "10^8 \\times 2,500 = 2.5 \\times 10^{11} \\quad (\\text{2500億回のLLM推論})\n",
    "$$\n",
    "\n",
    "これはAPIコストおよび処理時間の観点で**天文学的なリソース**を必要とするため、全数計算は事実上不可能である。したがって、この理論モデルの精度を維持しつつ、計算量を劇的に削減する工夫（サンプリング、クラスタリング等）が必要となる。\n",
    "\n",
    "\n",
    "## 5. 解決策：誘導点を用いた変分スパース近似 (Sparse Variational Approach with Inducing Points)\n",
    "\n",
    "ガウス過程回帰 (GPR) における計算量削減テクニックである **「誘導点 (Inducing Points)」** の概念を応用する。\n",
    "\n",
    "### 5.1 基本思想：Inducing Points (誘導点)\n",
    "1億人のADID ($N$) を全て計算に使うのではなく、そのデータ空間全体を少数の「仮想的な代表点（誘導点 $Z$）」で近似表現する。\n",
    "\n",
    "- **Full Data ($X$)**: 実際のADID特徴量（$N \\approx 10^8$）。計算不能。\n",
    "- **Inducing Points ($Z$)**: データ全体の分布を最適に記述できる「仮想的なユーザープロファイル」（$M \\approx 20 \\sim 50$）。\n",
    "\n",
    "この $Z$ は、既存のADIDから選ぶのではなく、**変分下界 (ELBO) を最大化するように、特徴空間内で最適化（学習）された「最も説明力の高い仮想ペルソナ」** である。\n",
    "\n",
    "### 5.2 アルゴリズム詳細\n",
    "\n",
    "#### Step 1: 誘導点 $Z$ の配置最適化\n",
    "場所 $L$ に存在する全ADIDの特徴量分布 $p(X|L)$ を近似するために、 $M$ 個の誘導点 $Z = \\{z_1, \\dots, z_M\\}$ を配置する。\n",
    "\n",
    "これは、変分法（Variational Inference）を用いて、実際のデータ $X$ と誘導点 $Z$ の間の情報損失（KL Divergence）を最小化する問題として定式化される。\n",
    "\n",
    "$$\n",
    "Z^* = \\underset{Z}{\\text{argmin}} \\text{KL}[p(X|L) || q(X|Z)]\n",
    "$$\n",
    "\n",
    "これにより、「単なるクラスタリングの重心」よりも、**「データの分散や特異点をカバーしつつ、全体を疎 (Sparse) に表現できる最適な点」** が自動的に求まる。\n",
    "\n",
    "#### Step 2: カーネル法による重み付け (Kernel Smoothing)\n",
    "ある場所 $L$ にいる実際のユーザー群が、どの誘導点 $z_m$ に近いかを表す「親和度」をカーネル関数 $k(\\cdot, \\cdot)$ で計算する。\n",
    "\n",
    "$$\n",
    "w_m = \\sum_{A \\in L} k(\\mathbf{x}_A, z_m)\n",
    "$$\n",
    "\n",
    "- $k(\\mathbf{x}_A, z_m)$: 実際のユーザー $A$ の特徴ベクトルと、誘導点 $z_m$ の類似度。\n",
    "- これにより、場所 $L$ が「どの誘導点（ペルソナ）の成分を強く持っているか」が重み $w$ として算出される。\n",
    "\n",
    "#### Step 3: 誘導点に対するLLM推論 (Sparse Inference)\n",
    "**LLMによる推論は、この $M$ 個の誘導点 $Z$ に対してのみ実行する。**\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{z_m} = \\text{Embed}(\\text{LLM}(\\text{Prompt}(z_m, L)))\n",
    "$$\n",
    "\n",
    "- **入力**: 最適化された仮想プロファイル $z_m$（例: 特徴空間上の座標としてのペルソナ）。\n",
    "- **出力**: そのペルソナが場所 $L$ で持つ文脈ベクトル。\n",
    "- **計算回数**: $N$ 回ではなく $M$ 回（$20 \\sim 50$ 回）で済む。\n",
    "\n",
    "#### Step 4: 文脈ベクトルの再構成 (Reconstruction)\n",
    "最終的な場所 $L$ のベクトル $\\mathbf{v}_L$ は、誘導点のベクトル $\\mathbf{v}_{z_m}$ の線形結合として予測（回帰）される。\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_L \\approx \\sum_{m=1}^{M} \\alpha_m \\cdot \\mathbf{v}_{z_m}\n",
    "$$\n",
    "(ここで $\\alpha_m$ は Step 2 で求めた重み $w_m$ に基づく係数)\n",
    "\n",
    "### 5.3 この手法の利点 (Why Sparse GP?)\n",
    "\n",
    "1.  **計算コストの圧倒的削減**:\n",
    "    - 計算オーダーは $O(N)$ から $O(M^2)$ または $O(NM)$ に下がる。$M$ は非常に小さいため（数十）、現実的な時間で計算可能。\n",
    "2.  **外れ値への対応 (Robustness)**:\n",
    "    - K-Meansのような単純平均では「外れ値」が重心をずらしてしまうが、Gaussian Processベースの誘導点はデータの「広がり（分散）」も考慮するため、ノイズに強い。\n",
    "3.  **連続空間での補間**:\n",
    "    - 誘導点は実在するADIDである必要がない。特徴空間上の「最適な中間地点」を仮想的に生成できるため、離散的なADIDだけでは表現しきれない「平均的なペルソナ」や「境界的なペルソナ」を表現できる。\n",
    "\n",
    "### 6. 結論 (Summary)\n",
    "**Sparse Variational approach (Inducing Points)** を採用することで、以下のパイプラインが完成する。\n",
    "\n",
    "1.  Unity CatalogからADIDデータ ($10^8$) をロード。\n",
    "2.  各場所について、データを代表する **少数の誘導点 ($Z$)** を変分学習で特定。\n",
    "3.  その **数十個の誘導点だけ** をLLMに入力し、文脈ベクトルを生成。\n",
    "4.  カーネル法を用いて元のデータ分布に射影し、場所のベクトルを合成。\n",
    "\n",
    "これにより、理論的な正しさを保ったまま、天文学的な計算コストを現実的な範囲に収めることができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモ：\n",
    "# cohort.npzは以下のようなデータ構成になっている\n",
    "# cohort.npz\n",
    "#     |-- data              : 計算済みコホート係数行列\n",
    "#     |-- indices           : データの位置指定子(列)\n",
    "#     |-- indptr            : 行ごとのスライスインデックス\n",
    "#     |-- shape             : コホート係数行列の形(ADIDのリスト × コホートキャプションのリスト)\n",
    "#     |-- adid_list         : ADIDのリスト(列)\n",
    "#     |-- business_codelist : コホートキャプションIDのリスト(行)\n",
    "TARGET      = \"/Volumes/stgadintedmpadintedi/featurestore/behaviorvector/cohort.npz\"\n",
    "npz         = np.load(TARGET, allow_pickle=True)\n",
    "np_codelist = npz[\"business_codelist\"]\n",
    "\n",
    "\n",
    "# CODELISTに対するキャプションリストを取得\n",
    "NAVIT_BUSINESS_TABLE = \"adinte_datainfrastructure.list.navit_business\"\n",
    "sdf_navit_business   = spark.read.table(NAVIT_BUSINESS_TABLE)\\\n",
    "\t\t\t\t\t\t\t.select(['BUSINESS_CODE', 'BUSINESS_NAME_S'])\\\n",
    "                            .join(spark.createDataFrame([(elem,) for elem in np_codelist.tolist()], ['BUSINESS_CODE']), on='BUSINESS_CODE', how='inner')\n",
    "\n",
    "sdf_navit_business.toPandas().to_csv('cohort_caption_list.csv', index=False, header=True)\n",
    "pdf_navit_business   = pd.read_csv('cohort_caption_list.csv', header=0, dtype={'BUSINESS_CODE': str, 'BUSINESS_NAME_S':str})\n",
    "dict_code2name       = pdf_navit_business.set_index('BUSINESS_CODE')['BUSINESS_NAME_S'].to_dict()\n",
    "dict_code2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmClient  = AsyncOpenAI(base_url=AI_FOUNDRY_ENDPOINT, api_key=AI_FOUNDRY_API_KEY)\n",
    "system_msg = SystemMessage(content=(\n",
    "\t\t\t\t\"あなたは、特定の場所・施設名から、そこに集まる人々の輪郭を鮮明に描き出す高度な空間データアナリストです。\\n\"\n",
    "                \"それぞれの場所に対し、その空間の具体的な情景や特性、利用者の属性、感覚、行動パターンを深掘りし、以下のJSON形式で分析結果を出力してください。\\n\\n\"\n",
    "\n",
    "\t\t\t\t\"【目的】\\n\"\n",
    "\t\t\t\t\"この出力は、単語の分散表現（文脈ベクトル）を生成するための学習データとして使用されます。\\n\"\n",
    "    \t\t\t\"そのため、一般的・抽象的な説明ではなく、その場所に強く紐付く「具体的な名詞（物体・商品・設備）」や「動詞（動作）」を含んだ、粒度の高い描写が必要です。\\n\\n\"\n",
    "\n",
    "\t\t\t\t\"【出力形式（厳守）】\\n\"\n",
    "\t\t\t\t\"回答は必ず以下のJSON形式のみを出力してください。\\n\"\n",
    "\t\t\t\t\"各場所・施設名をキーとし、150文字以内の短文としてまとめてください。\\n\"\n",
    "\t\t\t\t\"各場所につき、多様な観点から **20個** の短文リストを作成。\\n\\n\"\n",
    "\t\t\t\t\"Markdown記法（```json 等）は含めず、生のJSONテキストのみを返してください。\\n\\n\"\n",
    "                \"\"\"\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"入力された場所・施設名1\": [\"具体的なペルソナと行動1（情景＋属性＋感覚＋場所＋行為）\", \"具体的なペルソナと行動2（情景＋属性＋感覚＋場所＋行為）\", ...],\n",
    "\t\t\t\t\t\"入力された場所・施設名2\": [\"具体的なペルソナと行動3（情景＋属性＋感覚＋場所＋行為）\", ...],\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\"\"\"\n",
    "\t\t\t\t\"\\n\\n\"\n",
    "\t\t\t\t\n",
    "\t\t\t\t\"【抽出・生成のルール】\\n\"\n",
    "\t\t\t\t\"1. 語彙の解像度\\n\"\n",
    "                \"- 単語の羅列ではなく、情景が浮かぶ「属性＋具体的な状況＋行動」のセットで記述してください。\\n\"\n",
    "\t\t\t\t\"- NG例: 「公園」「運動」「サラリーマン」\\n\"\n",
    "\t\t\t\t\"- OK例: 「週末の親水公園で大型犬を遊ばせる愛犬家」「深夜の24時間ジムで大会に向けて追い込むトレーニー」「早朝の駅ビルでPC作業をするノマドワーカー」\\n\"\n",
    "\t\t\t\t\"- NG例: 「人々が運動している」\\n\"\n",
    "\t\t\t\t\"- OK例: 「ダンベルの金属音が響く中、鏡の前でフォームを確認するタンクトップの男性」\\n\"\n",
    "\t\t\t\t\"- NG例: 「静かなカフェ」\\n\"\n",
    "\t\t\t\t\"- OK例: 「エスプレッソマシンの蒸気音と、MacBookのキーボードを叩く音が混ざり合う」\\n\\n\"\n",
    "\n",
    "\t\t\t\t\"2. 多角的な視点を取り入れる（以下の要素をミックスする）\\n\"\n",
    "\t\t\t\t\"- 【時間】: 早朝の静けさ、ランチタイムの行列、深夜の気配\\n\"\n",
    "\t\t\t\t\"- 【感覚】: コーヒーの香り、塩素の匂い、エアコンの冷気、BGMの重低音\\n\"\n",
    "\t\t\t\t\"- 【対人】: 一人での没頭、友人との談笑、家族連れの喧騒\\n\\n\"\n",
    "\n",
    "\t\t\t\t\"3. 文体および文量\\n\"\n",
    "\t\t\t\t\"- 「〜です」「〜ます」は不要。体言止めや現在進行形で、情景を切り取るように記述する。\\n\"\n",
    "\t\t\t\t\"- 1文あたり120文字程度を推奨。\"\n",
    "\t\t\t\t\"- 入力された場所・施設名ごとに20個づつ抽出してください。\\n\\n\"\n",
    "\t\t\t))\n",
    "\n",
    "async def fetch_analysis(semaphore:asyncio.Semaphore, user_msg:str, keys:List):\n",
    "\tmax_retry = 5\n",
    "\tfor idx in range(max_retry):\n",
    "\t\tidx_temperature = TEMPERATURE * (0.9 ** idx)\n",
    "\t\ttry:\n",
    "\t\t\tasync with semaphore:\n",
    "\t\t\t\tresponse     = await llmClient.chat.completions.create(\n",
    "\t\t\t\t\t\t\t\t\t\tmessages=[system_msg, user_msg],\n",
    "\t\t\t\t\t\t\t\t\t\ttools=None,\n",
    "\t\t\t\t\t\t\t\t\t\ttool_choice=None,\n",
    "\t\t\t\t\t\t\t\t\t\tmax_tokens=MAX_TOKENS,\n",
    "\t\t\t\t\t\t\t\t\t\ttemperature=idx_temperature,\n",
    "\t\t\t\t\t\t\t\t\t\ttop_p=TOP_P,\n",
    "\t\t\t\t\t\t\t\t\t\tmodel=AI_FOUNDRY_MODEL\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\traw_content  = response.choices[0].message.content\n",
    "\n",
    "\t\t\tcontent_dict = json.loads(raw_content)\n",
    "\t\t\tmissing      = set(keys) - set(content_dict.keys())\n",
    "\t\t\texcess       = set(content_dict.keys()) - set(keys)\n",
    "\t\t\t\n",
    "\t\t\tif missing:\n",
    "\t\t\t\traise ValueError(f\"出力キーが不足しています。Missing: {missing}\")\n",
    "\t\t\tif excess:\n",
    "\t\t\t\tfor key in excess:\n",
    "\t\t\t\t\tdel content_dict[key]\n",
    "\n",
    "\t\t\treturn keys, content_dict\n",
    "\t\t\t\n",
    "\t\texcept json.JSONDecodeError as e:\n",
    "\t\t\tprint(f\"[Attempt {idx+1}] Decode Error:: {e}\")\n",
    "\t\t\tprint(raw_content)\n",
    "\t\t\tprint()\n",
    "\n",
    "\t\t\t# 一旦、サーバー負荷の軽減しつつリトライ\n",
    "\t\t\tawait asyncio.sleep(1)\n",
    "\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"[Attempt {idx+1}] API Error: {e}\")\n",
    "\n",
    "\t\t\t# 一旦、サーバー負荷の軽減しつつリトライ\n",
    "\t\t\tawait asyncio.sleep(3)\n",
    "\t\n",
    "\tprint(f\"Failed all {max_retry} attempts for this batch.\")\n",
    "\treturn keys, {}\n",
    "\n",
    "async def main():\n",
    "    semaphore = asyncio.Semaphore(50)\n",
    "    tasks     = []\n",
    "    for idx in range(0, len(data_list), 3):\n",
    "        set_place = data_list[idx : idx+3]\n",
    "        user_msg  = UserMessage(content=json.dumps(set_place))\n",
    "        tasks.append(fetch_analysis(semaphore, user_msg, set_place))\n",
    "    \n",
    "    results       = await tqdm_asyncio.gather(*tasks)\n",
    "    analysis_data = {}\n",
    "    danger_set    = set()\n",
    "    for keys, result in results:\n",
    "        if result == {}: danger_set.update(keys)\n",
    "        else:            analysis_data |= result\n",
    "    \n",
    "    return analysis_data, danger_set\n",
    "\n",
    "data_list                 = [dict_code2name[elem] for elem in np_codelist.tolist()]\n",
    "analysis_data, danger_set = await main()\n",
    "analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def correct_danger(danger_set:set):\n",
    "    semaphore = asyncio.Semaphore(50)\n",
    "    tasks     = []\n",
    "    for elem in danger_set:\n",
    "        user_msg = UserMessage(content=f\"['{elem}']\")\n",
    "        tasks.append(fetch_analysis(semaphore, user_msg, [elem]))\n",
    "    \n",
    "    results      = await tqdm_asyncio.gather(*tasks)\n",
    "    correct_data = {}\n",
    "    true_danger  = set()\n",
    "    for keys, result in results:\n",
    "        if result == {}: true_danger.update(keys)\n",
    "        else:            correct_data |= result\n",
    "    \n",
    "    return correct_data, true_danger\n",
    "\n",
    "correct_data, true_danger = await correct_danger(danger_set)\n",
    "correct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3463fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモ：\n",
    "# true_dangerがどうしても、発生してしまう\n",
    "# このセルで手動で、問題の解決を図ること\n",
    "\n",
    "final_data = analysis_data | correct_data\n",
    "print(len(data_list))\n",
    "print(len(final_data))\n",
    "print(true_danger)\n",
    "print()\n",
    "\n",
    "# target   = '不動産取引・商業施設設計業'\n",
    "# user_msg = UserMessage(content=f\"['{target}']\")\n",
    "# print(await fetch_analysis(asyncio.Semaphore(1), user_msg, [target]))\n",
    "# print()\n",
    "\n",
    "# target   = '駐車場・駐輪場関連'\n",
    "# user_msg = UserMessage(content=f\"['{target}']\")\n",
    "# print(await fetch_analysis(asyncio.Semaphore(1), user_msg, [target]))\n",
    "# print()\n",
    "\n",
    "# target   = '自動車・オートバイ・自転車・ドライブ関連'\n",
    "# user_msg = UserMessage(content=f\"['{target}']\")\n",
    "# print(await fetch_analysis(asyncio.Semaphore(1), user_msg, [target]))\n",
    "# print()\n",
    "\n",
    "# JSON形式でバックアップ\n",
    "with open('sentence-traindata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_data, f, indent=4, ensure_ascii=False)\n",
    "with open('sentence-traindata.json', 'r', encoding='utf-8') as f:\n",
    "    final_data = json.load(f)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c07ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model         = SentenceTransformer('cl-nagoya/ruri-v3-130m')\n",
    "count_list    = [len(final_data[key]) for key in final_data]\n",
    "list_location = [scene                for key in final_data for scene in final_data[key]]\n",
    "np_matrix     = model.encode(list_location, normalize_embeddings=True)  # (スポット数N × シーン数M) × 512\n",
    "\n",
    "indices       = np.cumsum(count_list)[:-1]\n",
    "final_matrix  = np.array([chunk.mean(axis=0) for chunk in np.split(np_matrix, indices)])\n",
    "l2norm_vector = np.linalg.norm(final_matrix, axis=1, keepdims=True)\n",
    "final_matrix  = final_matrix / np.maximum(l2norm_vector, 1e-10)\n",
    "final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9219e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモ：\n",
    "# final_matrixの行部分の順番は、バラバラになっている\n",
    "# これをnp_codelistと同期済みのdata_listを利用してソート・整形する\n",
    "\n",
    "place_names   = {elem:idx for idx, elem in enumerate(data_list)}\n",
    "np_places     = np.array([place_names[key] for key in final_data])\n",
    "\n",
    "sort_indices  = np.argsort(np_places)\n",
    "sorted_places = np.array(data_list)\n",
    "sorted_matrix = final_matrix[sort_indices, :]\n",
    "sorted_matrix = sorted_matrix.astype(np.float32)\n",
    "\n",
    "NPZ_PATH = 'cohort_caption_matrix.npz'\n",
    "np.savez_compressed(\n",
    "    NPZ_PATH,\n",
    "    data=sorted_matrix,\n",
    "    business_placelist=sorted_places,\n",
    "    dict_code2name=np.array(dict_code2name)\n",
    ")\n",
    "\n",
    "sorted_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8f577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
