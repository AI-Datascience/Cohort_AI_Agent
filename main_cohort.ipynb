{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6af442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing      import cast\n",
    "from logging     import Logger, getLogger\n",
    "from openai      import OpenAI\n",
    "\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "\n",
    "\n",
    "from url_scraper import fetch_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b343d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数の取得\n",
    "AI_FOUNDRY_ENDPOINT = os.environ.get(\"AI_FOUNDRY_ENDPOINT\")\n",
    "AI_FOUNDRY_API_KEY  = os.environ.get(\"AI_FOUNDRY_API_KEY\")\n",
    "AI_FOUNDRY_MODEL    = os.environ.get(\"AI_FOUNDRY_MODEL\")\n",
    "MAX_TOKENS          = os.environ.get(\"MAX_TOKENS\")\n",
    "TEMPERATURE         = os.environ.get(\"TEMPERATURE\")\n",
    "TOP_P               = os.environ.get(\"TOP_P\")\n",
    "\n",
    "# メモ：\n",
    "# ウィジット経由でのパラメータの取得方法では、無条件にパラメータの型がStringに変換されてしまう\n",
    "# そのため、受け取ったパラメータを適切に型変換する必要がある\n",
    "MAX_TOKENS  = int(MAX_TOKENS)\n",
    "TEMPERATURE = float(TEMPERATURE)\n",
    "TOP_P       = float(TOP_P)\n",
    "\n",
    "\n",
    "# 簡易デバッグ用\n",
    "print(f'AI_FOUNDRY_ENDPOINT: {AI_FOUNDRY_ENDPOINT}')\n",
    "print(f'AI_FOUNDRY_API_KEY:  {AI_FOUNDRY_API_KEY}')\n",
    "print(f'AI_FOUNDRY_MODEL:    {AI_FOUNDRY_MODEL}')\n",
    "print(f'MAX_TOKENS:          {MAX_TOKENS}')\n",
    "print(f'TEMPERATURE:         {TEMPERATURE}')\n",
    "print(f'TOP_P:               {TOP_P}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger    = getLogger(__name__)\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "\n",
    "LP_URL   = \"https://lp.br-lb.com/\"\n",
    "\n",
    "res_dict = await fetch_web(logger, semaphore, LP_URL)\n",
    "print(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45986cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages  = []\n",
    "messages.append(SystemMessage(content=(\n",
    "\t\t\t\"あなたは、商品記事の内容を分析し、マーケティングに必要な情報を抽出する専門家です。\\n\"\n",
    "\t\t\t\"ユーザーが提供するスクレイピングされた商品情報を読み取り、以下の3つの観点で分析し、単語リスト（カンマ区切り、または箇条書き）として回答してください。\\n\\n\"\n",
    "\t\t\t\n",
    "\t\t\t\"1. 物理的な場所・環境：その商品が実際に使われる具体的な場所（例：リビング、キャンプ場、オフィスなど）\\n\"\n",
    "\t\t\t\"2. 利用シーン・場面：どのような状況やタイミングで使われるか（例：朝のルーティン、テレワーク中、緊急時など）\\n\"\n",
    "\t\t\t\"3. ユーザーの行動・心理特性：その商品を選ぶ人の特徴や目的（例：時短重視、健康志向、ミニマリストなど）\\n\\n\"\n",
    "\t\t\t\n",
    "\t\t\t\"【制約事項】\\n\"\n",
    "\t\t\t\"・解説や文章は不要です。抽出した単語のみを列挙してください。\\n\"\n",
    "\t\t\t\"・記事から直接読み取れない場合でも、商品の性質から論理的に推論できる内容は含めてください。\"\n",
    "        )))\n",
    "messages.append(UserMessage(content=json.dumps(res_dict)))\n",
    "\n",
    "llmClient = OpenAI(base_url=AI_FOUNDRY_ENDPOINT, api_key=AI_FOUNDRY_API_KEY)\n",
    "response  = llmClient.chat.completions.create(\n",
    "\t\t\t\tmessages=messages,\n",
    "\t\t\t\ttools=None,\n",
    "\t\t\t\ttool_choice=None,\n",
    "\t\t\t\tmax_tokens=MAX_TOKENS,\n",
    "\t\t\t\ttemperature=TEMPERATURE,\n",
    "\t\t\t\ttop_p=TOP_P,\n",
    "\t\t\t\tmodel=AI_FOUNDRY_MODEL\n",
    "\t\t\t)\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662cc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
